{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arhammxo/mealMedic/blob/main/tts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asYG7lK7n6u0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/jaywalnut310/vits.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd vits"
      ],
      "metadata": {
        "id": "qhLrZq6PTa8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/vits/requirements.txt"
      ],
      "metadata": {
        "id": "jrsyLvZMTd8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/vits/monotonic_align"
      ],
      "metadata": {
        "id": "-bhzdHnjT3yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "7vF8aYrZUlUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir monotonic_align"
      ],
      "metadata": {
        "id": "iPJnV16iVcoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "metadata": {
        "id": "sMlZlSBuUAEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://indic-asr-public.objectstore.e2enetworks.net/svarah.tar"
      ],
      "metadata": {
        "id": "NzbqyFwWWeKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf svarah.tar"
      ],
      "metadata": {
        "id": "3xXojKk2XFsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd svarah\n",
        "!ls"
      ],
      "metadata": {
        "id": "uH_p850jYNDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from typing import List, Dict\n",
        "import os\n",
        "\n",
        "def read_json_lines(file_path: str) -> List[Dict]:\n",
        "    \"\"\"Read JSON Lines file and return list of dictionaries.\"\"\"\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():  # Skip empty lines\n",
        "                data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "def format_line(entry: Dict) -> str:\n",
        "    \"\"\"Format entry to required format: path_to_wav|transcript\"\"\"\n",
        "    return f\"{entry['audio_filepath']}|{entry['text']}\"\n",
        "\n",
        "def split_and_save_data(data: List[Dict], output_dir: str, train_ratio=0.8, test_ratio=0.1, val_ratio=0.1):\n",
        "    \"\"\"Split data and save to files.\"\"\"\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Shuffle data\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # Calculate split indices\n",
        "    total = len(data)\n",
        "    train_end = int(total * train_ratio)\n",
        "    test_end = train_end + int(total * test_ratio)\n",
        "\n",
        "    # Split data\n",
        "    train_data = data[:train_end]\n",
        "    test_data = data[train_end:test_end]\n",
        "    val_data = data[test_end:]\n",
        "\n",
        "    # Save splits to files\n",
        "    splits = {\n",
        "        'train.txt': train_data,\n",
        "        'test.txt': test_data,\n",
        "        'val.txt': val_data\n",
        "    }\n",
        "\n",
        "    for filename, split_data in splits.items():\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            for entry in split_data:\n",
        "                f.write(format_line(entry) + '\\n')\n",
        "\n",
        "        # Print statistics\n",
        "        print(f\"{filename}: {len(split_data)} entries ({len(split_data)/total*100:.1f}%)\")\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    input_file = 'svarah_manifest.json'  # Replace with your input file path\n",
        "    output_dir = 'splits'     # Output directory for split files\n",
        "\n",
        "    # Read data\n",
        "    print(\"Reading data...\")\n",
        "    data = read_json_lines(input_file)\n",
        "    print(f\"Total entries: {len(data)}\")\n",
        "\n",
        "    # Split and save data\n",
        "    print(\"\\nSplitting and saving data...\")\n",
        "    split_and_save_data(data, output_dir)\n",
        "\n",
        "    print(\"\\nDone! Files have been saved in the 'splits' directory.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "AgGsUwXWYUDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/vits\n",
        "!ls"
      ],
      "metadata": {
        "id": "LOB9P63wZU0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install espeak -y"
      ],
      "metadata": {
        "id": "h7Fds5EPaEYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install espeakng\n",
        "!pip install --upgrade espeakng\n",
        "\n",
        "# After installing, restart the runtime"
      ],
      "metadata": {
        "id": "Qv26g5oXboBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess.py --text_index 1 --filelists /content/vits/monotonic_align/svarah/splits/train.txt /content/vits/monotonic_align/svarah/splits/val.txt /content/vits/monotonic_align/svarah/splits/test.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ac1Ti9b5ZZvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conf.py\n",
        "\n",
        "import json\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "def create_vits_config(\n",
        "    train_filelist: str,\n",
        "    val_filelist: str,\n",
        "    output_path: str,\n",
        "    sampling_rate: int = 22050,\n",
        "    batch_size: int = 32,\n",
        "    n_speakers: int = 0,\n",
        "    epochs: int = 20000,\n",
        "    is_cleaned_text: bool = True,\n",
        "    language_cleaners: list = [\"english_cleaners2\"]\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a VITS configuration file based on input parameters.\n",
        "\n",
        "    Args:\n",
        "        train_filelist: Path to training filelist\n",
        "        val_filelist: Path to validation filelist\n",
        "        output_path: Where to save the config file\n",
        "        sampling_rate: Audio sampling rate\n",
        "        batch_size: Training batch size\n",
        "        n_speakers: Number of speakers (0 for single speaker)\n",
        "        epochs: Number of training epochs\n",
        "        is_cleaned_text: Whether text has been cleaned\n",
        "        language_cleaners: List of text cleaners to apply\n",
        "    \"\"\"\n",
        "\n",
        "    config = {\n",
        "        \"train\": {\n",
        "            \"log_interval\": 200,\n",
        "            \"eval_interval\": 1000,\n",
        "            \"seed\": 1234,\n",
        "            \"epochs\": epochs,\n",
        "            \"learning_rate\": 2e-4,\n",
        "            \"betas\": [0.8, 0.99],\n",
        "            \"eps\": 1e-9,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"fp16_run\": True,\n",
        "            \"lr_decay\": 0.999875,\n",
        "            \"segment_size\": 8192,\n",
        "            \"init_lr_ratio\": 1,\n",
        "            \"warmup_epochs\": 0,\n",
        "            \"c_mel\": 45,\n",
        "            \"c_kl\": 1.0\n",
        "        },\n",
        "        \"data\": {\n",
        "            \"training_files\": train_filelist,\n",
        "            \"validation_files\": val_filelist,\n",
        "            \"text_cleaners\": language_cleaners,\n",
        "            \"max_wav_value\": 32768.0,\n",
        "            \"sampling_rate\": sampling_rate,\n",
        "            \"filter_length\": 1024,\n",
        "            \"hop_length\": 256,\n",
        "            \"win_length\": 1024,\n",
        "            \"n_mel_channels\": 80,\n",
        "            \"mel_fmin\": 0.0,\n",
        "            \"mel_fmax\": None,\n",
        "            \"add_blank\": True,\n",
        "            \"n_speakers\": n_speakers,\n",
        "            \"cleaned_text\": is_cleaned_text\n",
        "        },\n",
        "        \"model\": {\n",
        "            \"inter_channels\": 192,\n",
        "            \"hidden_channels\": 192,\n",
        "            \"filter_channels\": 768,\n",
        "            \"n_heads\": 2,\n",
        "            \"n_layers\": 6,\n",
        "            \"kernel_size\": 3,\n",
        "            \"p_dropout\": 0.1,\n",
        "            \"resblock\": \"1\",\n",
        "            \"resblock_kernel_sizes\": [3,7,11],\n",
        "            \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
        "            \"upsample_rates\": [8,8,2,2],\n",
        "            \"upsample_initial_channel\": 512,\n",
        "            \"upsample_kernel_sizes\": [16,16,4,4],\n",
        "            \"n_layers_q\": 3,\n",
        "            \"use_spectral_norm\": False\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Calculate optimal segment size based on sampling rate\n",
        "    config[\"train\"][\"segment_size\"] = int(8192 * (sampling_rate / 22050))\n",
        "\n",
        "    # Adjust filter_length and window parameters based on sampling rate\n",
        "    if sampling_rate != 22050:\n",
        "        scale_factor = sampling_rate / 22050\n",
        "        config[\"data\"][\"filter_length\"] = int(1024 * scale_factor)\n",
        "        config[\"data\"][\"hop_length\"] = int(256 * scale_factor)\n",
        "        config[\"data\"][\"win_length\"] = int(1024 * scale_factor)\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = Path(output_path).parent\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Save the configuration\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "\n",
        "    print(f\"Configuration file saved to: {output_path}\")\n",
        "    return config\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Generate VITS configuration file\")\n",
        "    parser.add_argument(\"--train_filelist\", required=True, help=\"Path to training filelist\")\n",
        "    parser.add_argument(\"--val_filelist\", required=True, help=\"Path to validation filelist\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Output path for config file\")\n",
        "    parser.add_argument(\"--sampling_rate\", type=int, default=22050, help=\"Audio sampling rate\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"Training batch size\")\n",
        "    parser.add_argument(\"--n_speakers\", type=int, default=0, help=\"Number of speakers (0 for single speaker)\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=20000, help=\"Number of training epochs\")\n",
        "    parser.add_argument(\"--no_cleaned_text\", action=\"store_false\", dest=\"is_cleaned_text\",\n",
        "                       help=\"Set this flag if text is not cleaned\")\n",
        "    parser.add_argument(\"--language_cleaners\", nargs=\"+\", default=[\"english_cleaners2\"],\n",
        "                       help=\"List of text cleaners to apply\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    create_vits_config(\n",
        "        train_filelist=args.train_filelist,\n",
        "        val_filelist=args.val_filelist,\n",
        "        output_path=args.output,\n",
        "        sampling_rate=args.sampling_rate,\n",
        "        batch_size=args.batch_size,\n",
        "        n_speakers=args.n_speakers,\n",
        "        epochs=args.epochs,\n",
        "        is_cleaned_text=args.is_cleaned_text,\n",
        "        language_cleaners=args.language_cleaners\n",
        "    )"
      ],
      "metadata": {
        "id": "drVuxLlsicwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python conf.py \\\n",
        "    --train_filelist \"/content/vits/monotonic_align/svarah/splits/train.txt\" \\\n",
        "    --val_filelist \"/content/vits/monotonic_align/svarah/splits/val.txt\" \\\n",
        "    --output \"configs/your_config.json\""
      ],
      "metadata": {
        "id": "nNVBhTLXe1Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py -c configs/your_config.json -m your_model_name"
      ],
      "metadata": {
        "id": "Heqw0JVMfbkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}